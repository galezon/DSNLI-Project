---
title: "GLM after binning."
output: html_notebook
---

Load libraries, custom functions, required data.
```{r, warning=FALSE}
library(ggplot2)
library(dplyr)
library(MASS)

source("../r_utils/load_data_post_binning.R")
source("../r_utils/summarize_obj.R")
source("../r_utils/powerset.R")
```


Read all required data.
```{r}
data = load_data_post_binning("../data/train.csv")
```


Now that all possible co-variates are factors, we will try to build the GLM. We will try to see (Poisson, over-dispersed Poisson, negative binomial) for frequency, and (gamma, logNormal) for severity. I now realized that I should have made a strict restriction on the number of bins, 16 for *AGEPH* is too much, and thus I don't want to consider interaction effects between *AGEPH* and other co-variates.

As a spoiler, here are the chosen models:
  * Poisson GLM (freq): log(nbrtotc) ~ agecar + sexp + fuelc + split + fleetc + coverp + powerc + 
    freq_codposs + freq_AGEPH + offset(log(duree))
  * NegBinom GLM (freq): log(nbrtotc) ~ agecar + fuelc + split + coverp + powerc + freq_codposs + freq_AGEPH
  * Gamma GLM (sev): log(avg_claim) ~ fuelc + split + sev_AGEPH + sev_codposs

# Finding a GLM model for frequency.

## Checking (subjective) candidates for interactions


A short aggregating function that gives us a plot allowing us to check for the presence of interaction effects.
```{r, warning=FALSE}

see_interaction = function(var1, var2, data) { # !!as.symbol(var) is needed

  agg_data =  data %>%
                dplyr::select(!!as.symbol(var1), !!as.symbol(var2), duree, nbrtotc) %>%
                group_by(!!as.symbol(var1), !!as.symbol(var2)) %>%
                summarize(total_claims = sum(nbrtotc), total_expo = sum(duree)) %>%
                ungroup() %>%
                mutate(claims_per_expo = total_claims/total_expo)
  plot1 = ggplot(agg_data, aes(fill=get(var1), y=claims_per_expo, x=get(var2))) + 
    geom_bar(position="dodge", stat="identity") + labs(x=var2) + labs(fill=var1)
  
  plot2 = ggplot(agg_data, aes(fill=get(var2), y=claims_per_expo, x=get(var1))) + 
    geom_bar(position="dodge", stat="identity") + labs(x=var1) + labs(fill=var2)
  
  gridExtra::grid.arrange(plot1, plot2, ncol=2)
}
```

Possible interaction effects.
```{r, warning=FALSE, echo=FALSE, results='hide',fig.keep='all'}
see_interaction("agecar", "fleetc", data)  # Interaction!
```
```{r, warning=FALSE, echo=FALSE, results='hide',fig.keep='all'}
see_interaction("usec", "fleetc", data)  # No interaction!
```
```{r, warning=FALSE, echo=FALSE, results='hide',fig.keep='all'}
see_interaction("agecar", "usec", data)  # Changes in >10 years, interesting
```
```{r, warning=FALSE, echo=FALSE, results='hide',fig.keep='all'}
see_interaction("sexp", "powerc", data)  # Mild Definite interaction
```
```{r, warning=FALSE, echo=FALSE, results='hide',fig.keep='all'}
see_interaction("sexp", "sportc", data)  # Mild interaction!
```
```{r, warning=FALSE, echo=FALSE, results='hide',fig.keep='all'}
see_interaction("split", "sportc", data)  # Interaction!
```
```{r, warning=FALSE, echo=FALSE, results='hide',fig.keep='all'}
see_interaction("split", "powerc", data)  # Slight interaction
```

## Poisson GLM

One should immediately.
```{r}
full_formula = nbrtotc ~ offset(log(duree)) + agecar + sexp + fuelc + split + usec + fleetc + sportc + coverp + powerc + freq_codposs + freq_AGEPH

# adding interaction effects, we only drop variables backwards from here
full_int_formula = update(full_formula, ~. + agecar*fleetc + usec*fleetc + agecar*usec + sexp*powerc + sexp*sportc + split*sportc + split*powerc)

freq_fam = poisson(link="log")

set.seed(0916778)
full_glm = glm(full_formula, family=freq_fam, data=data)

set.seed(0916778)
full_int_glm = glm(full_int_formula, freq_fam, data)
```

Let's see the result of these interaction terms. I will try dropping *usec*, and keep the idea that if we don't use the main effect then we shouldn't use the interaction either (meaning I will also drop *usec:fleetc* and *usec:agecar*).
```{r}
anova(full_int_glm, test="Chisq")
```

Let us try dropping the interaction effect *split:powerc*.
```{r}
freq_f1 = update(full_int_formula, ~. - usec - usec:fleetc - usec:agecar)
freq_glm1 = glm(freq_f1, family=freq_fam, data=data)
anova(freq_glm1, test="Chisq")
```

Looks like we should drop the *split:powerc* indeed. I also the liberty to check ahead for *sexp:sportc*, *agecar:fleetc* and *sexp:powerc* and we should drop them.
```{r}
freq_f2 = update(freq_f1, ~. - split:powerc - sexp:sportc - agecar:fleetc - sexp:powerc)
freq_glm2 = glm(freq_f2, freq_fam, data)
anova(freq_glm2, freq_glm1, test="Chisq")
```

What else can be dropped? If we try to drop *split:sportc*, the drop in deviance rejects the null. Let us switch to BIC.
```{r}
anova(freq_glm2, test="Chisq")
print("-------------------------------------------------------------------")
BIC(freq_glm2)
```

The BIC is actually smaller though. So, let us just drop it.
```{r}
freq_f3 = update(freq_f2, ~. - split:sportc)
freq_glm3 = glm(freq_f3, freq_fam, data)
BIC(freq_glm3) - BIC(freq_glm2)
```

Interesting point, the anova calls adds terms sequentially. If the terms are added as in the order in ANOVA, then adding *sportc* is deemed very important. However, in the full summary, the Wald-test (coefficient of *sportc* being 0 or alternative) says that *sportc* is not important at all!
```{r}
anova(freq_glm3, test="Chisq")
print("------------------------------------------------------------------")
summary(freq_glm3)
```

In fact, we can verify below. The null is nowhere even close to being rejected!
```{r}
freq_f4 = update(freq_f3, ~. - sportc)
freq_glm4 = glm(freq_f4, freq_fam, data)
anova(freq_glm4, freq_glm3, test="Chisq")
```

It seems like I should trust the Wald-test in the summary more than I should trust the p-values of adding terms one-by-one (what anova does). In that spirit, I can perhaps join together some categoricals, for example: joining together some postcodes. However I won't do that. I am also happy enough with the current frequency glm.
```{r}
summary(freq_glm4)
```

Let us now save the model. I might build several different GLMs for frequency and severity, and later try each combination on the validation set that we separated in the beginning.
```{r}
# saveRDS(freq_glm4, file="../models/freq_glm_poisson.Rda")
```

Residual plots. I can only say something about pearson residuals vs fitted. Despite the title of the first plot, the plot is actually of pearson residuals vs log of fitted values (does predicted values mean the linear predictions?). Since this is Poisson, we expect that as fitted value increases, the variance (and thus the residual) grows. However, we can see here that for small log(fitted values), the variance is very large, thus indicating over-dispersion.
```{r}
par(mfrow=c(2, 2))
plot(freq_glm4)
```

To see that again. One can clearly see that between 0.0-0.1 the variance is very large. 
```{r}
plot(cbind(freq_glm4$fitted.values, residuals(freq_glm4, type="pearson")),
     xlab="Fitted Values", ylab="Pearson Residuals")
abline(0, 1)  # should be a cone with center being this line, if variance
              # is indeed equal to mean (fitted value)
```

To once more confirm over-dispersion. However, even if I build an 
```{r}
sum(residuals(freq_glm4, type="pearson")^2)/freq_glm4$df.residual
```

## Negative Binomial GLM.

This is the model that I'm happy with, using only drop-in-deviance tests.
```{r}
nb_formula = update(full_int_formula, ~. - usec - usec:fleetc - usec:agecar - sportc - sportc:sexp - sportc:split -agecar:fleetc - split:powerc -sexp:powerc)

nbfreq_glm = glm.nb(nb_formula, data)
```

Last try with BIC. Improvement, actually.
```{r}
vars = c("sexp", "fleetc")
formulas = powerset_formula(vars, nb_formula, operation="-")

models = list()
BIC_vals = rep(0, length(formulas))
for (idx in 1:length(formulas)) {
  tmp_formula = formulas[[idx]]
  tmp_glm = glm.nb(tmp_formula, data)
  BIC_vals[idx] = BIC(tmp_glm)
  models[[idx]] = tmp_glm
}

print(BIC(nbfreq_glm))  # reference value
print(BIC_vals)
```

Check the best formula so far.
```{r}
nb_formula2 = formulas[[3]]
nb_formula2
```

Only 32 models, we can mass-search with BIC. None turns out better in terms of BIC.
```{r}
vars2 = c("agecar", "fuelc", "split", "coverp", "powerc")
formulas2 = powerset_formula(vars2, nb_formula2, operation="-")

models2 = list()
BIC_vals2 = rep(0, length(formulas2))
for (idx in 1:length(formulas2)) {
  tmp_formula = formulas2[[idx]]
  tmp_glm = glm.nb(tmp_formula, data)
  BIC_vals2[idx] = BIC(tmp_glm)
  models2[[idx]] = tmp_glm
}

print(BIC(models[[3]]))  # reference value
BIC_vals2[BIC_vals2 <= BIC(models[[3]])]
```

Save the NB model.
```{r}
saveRDS(models[[3]], file="../models/freq_glm_nb.Rda")
```


# Finding a GLM model for Severity.

Condition on nbrtotc > 0.
```{r}
sev_data = data %>%
  filter(nbrtotc > 0) %>%
  mutate(avg_claim = chargtot/nbrtotc)
```


## Check for interaction effects.

Same function as before, re-tooled.
```{r}
see_interaction2 = function(var1, var2, sev_data) { # !!as.symbol(var) is needed

  agg_data =  sev_data %>%
                dplyr::select(!!as.symbol(var1), !!as.symbol(var2), avg_claim) %>%
                group_by(!!as.symbol(var1), !!as.symbol(var2)) %>%
                summarize(avg_avg_claims = mean(avg_claim))
  
  plot1 = ggplot(agg_data, aes(fill=get(var1), y=avg_avg_claims, x=get(var2))) + 
    geom_bar(position="dodge", stat="identity") + labs(x=var2) + labs(fill=var1)
  
  plot2 = ggplot(agg_data, aes(fill=get(var2), y=avg_avg_claims, x=get(var1))) + 
    geom_bar(position="dodge", stat="identity") + labs(x=var1) + labs(fill=var2)
  
  gridExtra::grid.arrange(plot1, plot2, ncol=2)
}
```

Checking possible interactions. I will only include interaction terms that I tag as a "Yes!" below.
```{r}
see_interaction2("agecar", "fleetc", sev_data)  # Not rly
see_interaction2("usec", "fleetc", sev_data)  # Yes!
see_interaction2("agecar", "usec", sev_data)  # Mild
see_interaction2("sexp", "powerc", sev_data)  # Yes!
see_interaction2("sexp", "sportc", sev_data)  # No
see_interaction2("split", "sportc", sev_data)  # Yes!
see_interaction2("split", "powerc", sev_data)  # Yes!
```

## Gamma GLM.

I'm getting divergence errors, not enough data?

> That error message and the warning indicate that the algorithm
> (iteratively reweighted least squares or IRLS) for fitting the
> parameters cannot converge, which can be because the model is
> over-specified.
> https://stat.ethz.ch/pipermail/r-help/2009-December/416122.html

```{r}
sev_full_formula = avg_claim ~ agecar + sexp + fuelc + split + usec + fleetc + sportc + coverp + powerc + sev_AGEPH + sev_codposs + usec:fleetc + sexp:powerc + split:powerc + split:sportc

sev_fam = Gamma(link="log")
sev_full_glm = glm(sev_full_formula, sev_fam, sev_data)

summary(sev_full_gm, test="Chisq")
```

Now it converges, and we have many variables to drop. *AGEPH* is deemed not significant (Wald-test), since this is 8 levels I will drop this first.
```{r}
sev_formula = avg_claim ~ agecar + sexp + fuelc + split + usec + fleetc + sportc + coverp + powerc + sev_AGEPH + sev_codposs

sev_glm = glm(sev_formula, sev_fam, sev_data)

summary(sev_glm)
```

Dropping *AGEPH*. Borderline. Check BIC.
```{r}
sev_f1 = update(sev_formula, ~. - sev_AGEPH)
sev_glm1 = glm(sev_f1, sev_fam, sev_data)

anova(sev_glm1, sev_glm, test="Chisq")
```

So, we can't drop *AGEPH*.
```{r}
BIC(sev_glm) - BIC(sev_glm1)
```

Mass-search to see what is drop-able. Between the powerset of *agecar*, *sportc*, *fleetc*, *usec*, we will consider every single combination.
```{r}
sev_vars = c("agecar", "sportc", "fleetc", "usec")
formulas_list = powerset_formula(sev_vars, sev_formula, operation="-")

sev_models = list()
sev_BIC_vals = rep(0, length(formulas_list))
for (idx in 1:length(formulas_list)) {
  tmp_formula = formulas_list[[idx]]
  tmp_glm = glm(tmp_formula, sev_fam, sev_data)
  
  sev_models[[idx]] = tmp_glm
  sev_BIC_vals[idx] = BIC(tmp_glm)
}


ref_BIC = BIC(sev_glm)
which(sev_BIC_vals < ref_BIC)
```

We can drop *usec* and *sportc*.
```{r}
sev_mass_glm1 = sev_models[[8]]
sev_mass_glm2 = sev_models[[10]]

anova(sev_mass_glm1,sev_glm, test="Chisq")  # no usec
anova(sev_mass_glm2,sev_glm, test="Chisq")  # no usec and sportc
```

I did further analysis and we can also drop *coverp* and *powerc*.
```{r}
sev_f2 = update(sev_formula, ~. - usec - sportc - coverp - powerc)
sev_glm2 = glm(sev_f2, sev_fam, sev_data)
summary(sev_glm2)
```

We explore all possible combinations of dropping *agecar*, *sexp*, and *fleetc*. As it turns out, we can drop all three if we trust on drop-in-deviance test and ignore BIC values. I will do that, my only justification is that I prefer the model-specific test compared to the model agnostic one.
```{r}
sev_vars2 = c("agecar", "sexp", "fleetc")
formulas_list2 = powerset_formula(sev_vars2, sev_f2, operation="-")

sev_models2 = list()
sev_BIC_vals2 = rep(0, length(formulas_list2))
for (idx in 1:length(formulas_list2)) {
  print(paste("---------------IDX=", idx, "---------------"))
  tmp_formula = formulas_list2[[idx]]
  tmp_glm = glm(tmp_formula, sev_fam, sev_data)
  
  sev_models2[[idx]] = tmp_glm
  sev_BIC_vals2[idx] = BIC(tmp_glm)
  
  print(anova(tmp_glm, sev_glm2, test="Chisq"))
  print("------------------------------------------------------")
}


ref_BIC2 = BIC(sev_glm2)
which(sev_BIC_vals2 < ref_BIC2)
```

Curious if we can drop *AGEPH*.
```{r}
sev_f3 = update(sev_f2, ~. - sexp - fleetc - agecar)
sev_glm3 = glm(sev_f3, sev_fam, sev_data)

summary(sev_glm3)
```

Checking once more if we can drop *AGEPH*. BIC says no, but drop-in-deviance is borderline. Perhaps a visual aid?
```{r}
sev_f4 = update(sev_f3, ~. -sev_AGEPH)
sev_glm4 = glm(sev_f4, sev_fam, sev_data)

BIC(sev_glm4) - BIC(sev_glm3)
print("---------------------------------------------------------------------")
anova(sev_glm4, sev_glm3, test="Chisq")
print("---------------------------------------------------------------------")
summary(sev_glm4)
```

Final decision on to drop *AGEPH* or not. Looks like there are some difference. I decided not to drop *AGEPH*.
```{r}
q = sev_data %>%
  dplyr::select(sev_AGEPH, avg_claim) %>%
  group_by(sev_AGEPH) %>%
  summarize(avg_avg_claim = mean(avg_claim))

ggplot(data=q, aes(x=sev_AGEPH, y=avg_avg_claim)) +
  geom_bar(stat="identity")
  
```

Save our model.
```{r}
# saveRDS(sev_glm3, file="../models/sev_glm_gamma.Rda")
```













